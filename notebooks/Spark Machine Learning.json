{"paragraphs":[{"text":"%md ### Machine Learning with Spark\n\n&copy;2016, 2017 by Adam Breindel. All Rights Reserved.\n\n#### Legacy API vs. Modern API\n\n* ML Pipelines\n    * DataFrame\n    * Transformer / Estimator / Pipeline\n    * CrossValidator / ParamGridBuilder / Evaluator\n* RDD API in maintenance mode, will be deprecated, then removed (~ 3.0?)\n    * Still contains some features not present in new API (e.g., SVD, covariance matrix)\n\n#### Example with (R/ggplot) Diamonds dataset\n\n* Data manipulation (DataFrame, Transformer, Estimator)\n* Feature selection\n* Model building (Pipeline)\n* Evaluation (Evaluator)\n* Tuning\n* Crossvalidation (CrossValidator, ParamGridBuilder)","user":"anonymous","dateUpdated":"2017-02-19T12:15:01-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487532591326_907480540","id":"20170219-112951_1854979224","dateCreated":"2017-02-19T11:29:51-0800","dateStarted":"2017-02-19T12:15:01-0800","dateFinished":"2017-02-19T12:15:01-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7669","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Machine Learning with Spark</h3>\n<p>&copy;2016, 2017 by Adam Breindel. All Rights Reserved.</p>\n<h4>Legacy API vs. Modern API</h4>\n<ul>\n  <li>ML Pipelines\n    <ul>\n      <li>DataFrame</li>\n      <li>Transformer / Estimator / Pipeline</li>\n      <li>CrossValidator / ParamGridBuilder / Evaluator</li>\n    </ul>\n  </li>\n  <li>RDD API in maintenance mode, will be deprecated, then removed (~ 3.0?)\n    <ul>\n      <li>Still contains some features not present in new API (e.g., SVD, covariance matrix)</li>\n    </ul>\n  </li>\n</ul>\n<h4>Example with (R/ggplot) Diamonds dataset</h4>\n<ul>\n  <li>Data manipulation (DataFrame, Transformer, Estimator)</li>\n  <li>Feature selection</li>\n  <li>Model building (Pipeline)</li>\n  <li>Evaluation (Evaluator)</li>\n  <li>Tuning</li>\n  <li>Crossvalidation (CrossValidator, ParamGridBuilder)</li>\n</ul>\n</div>"}]}},{"text":"spark.read.option(\"header\", true).csv(\"data/diamonds.csv\").show","user":"anonymous","dateUpdated":"2017-02-19T11:41:53-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533117212_1110766400","id":"20170219-113837_1424131170","dateCreated":"2017-02-19T11:38:37-0800","dateStarted":"2017-02-19T11:41:50-0800","dateFinished":"2017-02-19T11:41:50-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7670"},{"text":"spark.read.option(\"header\", true).csv(\"data/diamonds.csv\").printSchema","user":"anonymous","dateUpdated":"2017-02-19T11:42:04-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533316425_1727578539","id":"20170219-114156_497727897","dateCreated":"2017-02-19T11:41:56-0800","dateStarted":"2017-02-19T11:42:04-0800","dateFinished":"2017-02-19T11:42:04-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7671"},{"text":"val data = spark.read.option(\"header\", true)\n                .option(\"inferSchema\", true)\n                .csv(\"data/diamonds.csv\")\ndata.show","user":"anonymous","dateUpdated":"2017-02-19T11:42:08-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533276943_849704143","id":"20170219-114116_1632005710","dateCreated":"2017-02-19T11:41:16-0800","dateStarted":"2017-02-19T11:42:08-0800","dateFinished":"2017-02-19T11:42:09-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7672"},{"text":"data.printSchema","user":"anonymous","dateUpdated":"2017-02-19T11:42:19-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533328697_-1838643691","id":"20170219-114208_638207268","dateCreated":"2017-02-19T11:42:08-0800","dateStarted":"2017-02-19T11:42:19-0800","dateFinished":"2017-02-19T11:42:19-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7673"},{"text":"%md We'll look at the features in more detail ... but right away we see we'll have to do something about string-typed features. \n\nThe price (label) is an integer, not a double. In many cases, an integer can be auto-widened to a double, but there may be some places we'll have to watch out.\n\nAlso, that \"\\_c0\" (a.k.a. the row number or row ID) ... not only is it not a feature, but it can leak irrelevant data:","user":"anonymous","dateUpdated":"2017-02-19T12:15:05-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533339615_-68398678","id":"20170219-114219_563237401","dateCreated":"2017-02-19T11:42:19-0800","dateStarted":"2017-02-19T12:15:05-0800","dateFinished":"2017-02-19T12:15:05-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7674","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>We&rsquo;ll look at the features in more detail &hellip; but right away we see we&rsquo;ll have to do something about string-typed features. </p>\n<p>The price (label) is an integer, not a double. In many cases, an integer can be auto-widened to a double, but there may be some places we&rsquo;ll have to watch out.</p>\n<p>Also, that &ldquo;_c0&rdquo; (a.k.a. the row number or row ID) &hellip; not only is it not a feature, but it can leak irrelevant data:</p>\n</div>"}]}},{"text":"z.show(data.select(\"_c0\", \"price\").sample(false, 0.01, 42))","user":"anonymous","dateUpdated":"2017-02-19T12:01:13-0800","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"scatterChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533349774_1881524072","id":"20170219-114229_63907511","dateCreated":"2017-02-19T11:42:29-0800","dateStarted":"2017-02-19T12:01:02-0800","dateFinished":"2017-02-19T12:01:02-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7675"},{"text":"// We'd better get rid of the row number and fix price:\n\nimport org.apache.spark.sql.types._\n\nval data2 = data.drop(\"_c0\").withColumn(\"label\", 'price cast DoubleType).drop(\"price\")\ndata2.show","user":"anonymous","dateUpdated":"2017-02-19T11:44:59-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533432866_-1861374525","id":"20170219-114352_1415218590","dateCreated":"2017-02-19T11:43:52-0800","dateStarted":"2017-02-19T11:44:59-0800","dateFinished":"2017-02-19T11:45:00-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7676"},{"text":"data2.describe(\"carat\", \"label\", \"x\", \"y\", \"z\").show","user":"anonymous","dateUpdated":"2017-02-19T11:47:32-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533499374_1800204137","id":"20170219-114459_1151417012","dateCreated":"2017-02-19T11:44:59-0800","dateStarted":"2017-02-19T11:47:32-0800","dateFinished":"2017-02-19T11:47:32-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7677"},{"text":"data2.filter(\"x <= 1 or y <= 1 or z <= 1\").show(100)","user":"anonymous","dateUpdated":"2017-02-19T11:48:51-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533526757_266392517","id":"20170219-114526_172033791","dateCreated":"2017-02-19T11:45:26-0800","dateStarted":"2017-02-19T11:48:51-0800","dateFinished":"2017-02-19T11:48:51-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7678"},{"text":"%md Now we need to do some processing with the categorical features: cut, color, and clarity.","user":"anonymous","dateUpdated":"2017-02-19T12:15:09-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533684375_-877234455","id":"20170219-114804_1000009167","dateCreated":"2017-02-19T11:48:04-0800","dateStarted":"2017-02-19T12:15:09-0800","dateFinished":"2017-02-19T12:15:09-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7679","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now we need to do some processing with the categorical features: cut, color, and clarity.</p>\n</div>"}]}},{"text":"z.show(data2.select(\"cut\").distinct)","user":"anonymous","dateUpdated":"2017-02-19T12:15:24-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533766540_942951294","id":"20170219-114926_309428837","dateCreated":"2017-02-19T11:49:26-0800","dateStarted":"2017-02-19T12:15:21-0800","dateFinished":"2017-02-19T12:15:22-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7680"},{"text":"data2.groupBy(\"cut\").count.show","user":"anonymous","dateUpdated":"2017-02-19T11:50:15-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533801417_1019329146","id":"20170219-115001_205712247","dateCreated":"2017-02-19T11:50:01-0800","dateStarted":"2017-02-19T11:50:15-0800","dateFinished":"2017-02-19T11:50:15-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7681"},{"text":"%md __In this example, we'll build a Linear Regression model.__ For this type of model, \nwe will want to convert these categorical variables into a one-hot, or \"dummy variable,\" representation,\nso we want to create a OneHotEncoder\n\n* https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.OneHotEncoder\n\nThe one-hot encoder takes a numeric value, so we need to convert the categorical values to numbers.\n\nWe can do that with a StringIndexer\n\n* https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.StringIndexer\n\n---\n\nThis is a good time to think about how `Transformers` and `Estimators` work and gain some design intuition.\n\nFirst, we want to be clear what the `StringIndexer` and `OneHotEncoder` are supposed to do.\n\nWhy might one be a transformer and the other an estimator? These two helpers could be built either as Transformers or Estimators. What factors would argue for/against using one pattern versus the other? Hint: there is a Spark JIRA to \"fix\" OneHotEncoder, perhaps in 2.2, to be an Estimator.\n\nNote that neither can be performed as a pure map operation. They both need to accumulate some bit of state, via a reduce, to then use in the map.\n\nEXTRA CREDIT: Try to locate these bits in the source code. Can you find where the \"reduce\" job is hidden in the OneHotEncoder (even though it's a transformer)?\n\n---\n\nSee if you can manually run these two helpers against the data.\n\n","user":"anonymous","dateUpdated":"2017-02-19T12:15:30-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533811224_825061600","id":"20170219-115011_934534280","dateCreated":"2017-02-19T11:50:11-0800","dateStarted":"2017-02-19T12:15:30-0800","dateFinished":"2017-02-19T12:15:30-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7682","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong>In this example, we&rsquo;ll build a Linear Regression model.</strong> For this type of model,<br/>we will want to convert these categorical variables into a one-hot, or &ldquo;dummy variable,&rdquo; representation,<br/>so we want to create a OneHotEncoder</p>\n<ul>\n  <li><a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.OneHotEncoder\">https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.OneHotEncoder</a></li>\n</ul>\n<p>The one-hot encoder takes a numeric value, so we need to convert the categorical values to numbers.</p>\n<p>We can do that with a StringIndexer</p>\n<ul>\n  <li><a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.StringIndexer\">https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.StringIndexer</a></li>\n</ul>\n<hr/>\n<p>This is a good time to think about how <code>Transformers</code> and <code>Estimators</code> work and gain some design intuition.</p>\n<p>First, we want to be clear what the <code>StringIndexer</code> and <code>OneHotEncoder</code> are supposed to do.</p>\n<p>Why might one be a transformer and the other an estimator? These two helpers could be built either as Transformers or Estimators. What factors would argue for/against using one pattern versus the other? Hint: there is a Spark JIRA to &ldquo;fix&rdquo; OneHotEncoder, perhaps in 2.2, to be an Estimator.</p>\n<p>Note that neither can be performed as a pure map operation. They both need to accumulate some bit of state, via a reduce, to then use in the map.</p>\n<p>EXTRA CREDIT: Try to locate these bits in the source code. Can you find where the &ldquo;reduce&rdquo; job is hidden in the OneHotEncoder (even though it&rsquo;s a transformer)?</p>\n<hr/>\n<p>See if you can manually run these two helpers against the data.</p>\n</div>"}]}},{"text":"// try it here","user":"anonymous","dateUpdated":"2017-02-19T11:53:37-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487533911695_267715330","id":"20170219-115151_209900794","dateCreated":"2017-02-19T11:51:51-0800","dateStarted":"2017-02-19T11:53:35-0800","dateFinished":"2017-02-19T11:53:35-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7683"},{"text":"%md Now let's automate this work a bit: we'll use functional collections to create our feature helpers, and a pipeline to wrap them","user":"anonymous","dateUpdated":"2017-02-19T12:15:34-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534015139_731691855","id":"20170219-115335_1690778894","dateCreated":"2017-02-19T11:53:35-0800","dateStarted":"2017-02-19T12:15:34-0800","dateFinished":"2017-02-19T12:15:34-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7684","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now let&rsquo;s automate this work a bit: we&rsquo;ll use functional collections to create our feature helpers, and a pipeline to wrap them</p>\n</div>"}]}},{"text":"import org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\n\nval categoricalFields = Seq(\"cut\", \"color\", \"clarity\")\n\nval indexers = categoricalFields.map(f => new StringIndexer().setInputCol(f).setOutputCol(f + \"Index\"))\n\nval encoders = categoricalFields.map(f => new OneHotEncoder().setInputCol(f + \"Index\").setOutputCol(f + \"Vec\"))\n\nval pipeline = new Pipeline().setStages( (indexers ++ encoders).toArray ).fit(data2)\n\npipeline.transform(data2).show","user":"anonymous","dateUpdated":"2017-02-19T11:54:03-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534033565_-2018514064","id":"20170219-115353_845492268","dateCreated":"2017-02-19T11:53:53-0800","dateStarted":"2017-02-19T11:54:00-0800","dateFinished":"2017-02-19T11:54:02-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7685"},{"text":"%md That looks pretty good. Next, we need to bring all of our features together into a single vector. \nThe `VectorAssembler` class, a `Transformer` (why?) does exactly that:","user":"anonymous","dateUpdated":"2017-02-19T12:15:36-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534040226_-1873063656","id":"20170219-115400_1179469190","dateCreated":"2017-02-19T11:54:00-0800","dateStarted":"2017-02-19T12:15:36-0800","dateFinished":"2017-02-19T12:15:36-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7686","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>That looks pretty good. Next, we need to bring all of our features together into a single vector.<br/>The <code>VectorAssembler</code> class, a <code>Transformer</code> (why?) does exactly that:</p>\n</div>"}]}},{"text":"val assembler = new VectorAssembler()\n  .setInputCols( (categoricalFields.map(_ + \"Vec\") ++ Seq(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\")).toArray )\n  .setOutputCol(\"features\")\n\nnew Pipeline()\n    .setStages( ((indexers ++ encoders) :+ assembler).toArray )\n    .fit(data2)\n    .transform(data2)\n    .drop(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\") // to save space on the screen!\n    .show","user":"anonymous","dateUpdated":"2017-02-19T11:57:21-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534094992_-1025785281","id":"20170219-115454_1035763807","dateCreated":"2017-02-19T11:54:54-0800","dateStarted":"2017-02-19T11:57:15-0800","dateFinished":"2017-02-19T11:57:16-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7687"},{"text":"%md Let's finish the pipeline by adding the Linear Regression algorithm","user":"anonymous","dateUpdated":"2017-02-19T12:15:38-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534104624_-2077842015","id":"20170219-115504_655775644","dateCreated":"2017-02-19T11:55:04-0800","dateStarted":"2017-02-19T12:15:38-0800","dateFinished":"2017-02-19T12:15:38-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7688","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Let&rsquo;s finish the pipeline by adding the Linear Regression algorithm</p>\n</div>"}]}},{"text":"import org.apache.spark.ml.regression._\n\nval lr = new LinearRegression()\n\nval completePipeline = new Pipeline().setStages( ((indexers ++ encoders) :+ assembler :+ lr).toArray )","user":"anonymous","dateUpdated":"2017-02-19T11:57:42-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534252858_-1002237333","id":"20170219-115732_467292383","dateCreated":"2017-02-19T11:57:32-0800","dateStarted":"2017-02-19T11:57:39-0800","dateFinished":"2017-02-19T11:57:40-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7689"},{"text":"%md Now we're ready to train and do an initial test","user":"anonymous","dateUpdated":"2017-02-19T12:15:41-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534259602_1229306288","id":"20170219-115739_2099637335","dateCreated":"2017-02-19T11:57:39-0800","dateStarted":"2017-02-19T12:15:41-0800","dateFinished":"2017-02-19T12:15:41-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7690","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now we&rsquo;re ready to train and do an initial test</p>\n</div>"}]}},{"text":"val Array(train, test) = data2.randomSplit(Array(0.75, 0.25), 42)\nval model = completePipeline.fit(train)\nval predictions = model.transform(test).select('label, 'prediction)\nz.show(predictions.sample(false, 0.05, 42))","user":"anonymous","dateUpdated":"2017-02-19T12:00:32-0800","config":{"colWidth":12,"enabled":true,"results":{"1":{"graph":{"mode":"scatterChart","height":300,"optionOpen":false,"setting":{"scatterChart":{"xAxis":{"name":"label","index":0,"aggr":"sum"},"yAxis":{"name":"prediction","index":1,"aggr":"sum"}}}},"helium":{}}},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534276033_-811386554","id":"20170219-115756_2109335244","dateCreated":"2017-02-19T11:57:56-0800","dateStarted":"2017-02-19T11:58:46-0800","dateFinished":"2017-02-19T11:58:52-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7691"},{"text":"%md Looks plausible ... but let's get some numbers using the `Evaluator` class.\n\n`Evaluator` is useful for \n\n* Obtaining performance statistics on our models\n\n* Enabling SparkML to obtains statistics on models that it build as part of automated hyperparameter tuning and cross validations","user":"anonymous","dateUpdated":"2017-02-19T12:15:42-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534326449_-317125424","id":"20170219-115846_704049924","dateCreated":"2017-02-19T11:58:46-0800","dateStarted":"2017-02-19T12:15:42-0800","dateFinished":"2017-02-19T12:15:42-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7692","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Looks plausible &hellip; but let&rsquo;s get some numbers using the <code>Evaluator</code> class.</p>\n<p><code>Evaluator</code> is useful for </p>\n<ul>\n  <li>\n  <p>Obtaining performance statistics on our models</p></li>\n  <li>\n  <p>Enabling SparkML to obtains statistics on models that it build as part of automated hyperparameter tuning and cross validations</p></li>\n</ul>\n</div>"}]}},{"text":"import org.apache.spark.ml.evaluation._\nval eval = new RegressionEvaluator()\neval.evaluate(predictions)","user":"anonymous","dateUpdated":"2017-02-19T12:03:18-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534586717_-1139381440","id":"20170219-120306_725391657","dateCreated":"2017-02-19T12:03:06-0800","dateStarted":"2017-02-19T12:03:14-0800","dateFinished":"2017-02-19T12:03:15-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7693"},{"text":"%md Ok ... let's see if we can wire Spark up to tune the model. In particular, \n\n1. we'll give Spark a set of hyperparamters to adjust, and some values to try\n2. let Spark build a series of tentative models using k-fold crossvalidation\n3. tell Spark what evaluator to use, so it knows which tentative models are better","user":"anonymous","dateUpdated":"2017-02-19T12:15:45-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534594725_-36291020","id":"20170219-120314_1557023944","dateCreated":"2017-02-19T12:03:14-0800","dateStarted":"2017-02-19T12:15:45-0800","dateFinished":"2017-02-19T12:15:45-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7694","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Ok &hellip; let&rsquo;s see if we can wire Spark up to tune the model. In particular, </p>\n<ol>\n  <li>we&rsquo;ll give Spark a set of hyperparamters to adjust, and some values to try</li>\n  <li>let Spark build a series of tentative models using k-fold crossvalidation</li>\n  <li>tell Spark what evaluator to use, so it knows which tentative models are better</li>\n</ol>\n</div>"}]}},{"text":"import org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.ml.tuning._\n\nval paramGrid = new ParamGridBuilder()\n  .addGrid(lr.elasticNetParam, Array(0.3, 0.7))\n  .addGrid(lr.regParam, Array(0.01, 0.1))\n  .build()\n\nval cv = new CrossValidator()\n  .setEstimator(completePipeline)\n  .setEvaluator(new RegressionEvaluator)\n  .setEstimatorParamMaps(paramGrid)\n  .setNumFolds(3)\n\nval cvModel = cv.fit(train)","user":"anonymous","dateUpdated":"2017-02-19T12:06:07-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534758015_-1851473389","id":"20170219-120558_532949922","dateCreated":"2017-02-19T12:05:58-0800","dateStarted":"2017-02-19T12:06:04-0800","dateFinished":"2017-02-19T12:06:20-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7695"},{"text":"%md How different was the performance across the different parameter sets?","user":"anonymous","dateUpdated":"2017-02-19T12:15:48-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534764606_-1668317589","id":"20170219-120604_1585803515","dateCreated":"2017-02-19T12:06:04-0800","dateStarted":"2017-02-19T12:15:48-0800","dateFinished":"2017-02-19T12:15:48-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7696","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>How different was the performance across the different parameter sets?</p>\n</div>"}]}},{"text":"cvModel.getEstimatorParamMaps.zip(cvModel.avgMetrics)","user":"anonymous","dateUpdated":"2017-02-19T12:15:55-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534793112_1685984619","id":"20170219-120633_688046917","dateCreated":"2017-02-19T12:06:33-0800","dateStarted":"2017-02-19T12:15:50-0800","dateFinished":"2017-02-19T12:15:50-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7697"},{"text":"%md After training the CrossValidatorModel, `cvModel.bestModel` will contain a model trained on all of the training data using the best hyperparams.\n\nHowever, we could also train that \"best model\" ourselves:","user":"anonymous","dateUpdated":"2017-02-19T12:15:59-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534816022_1797192376","id":"20170219-120656_1325278688","dateCreated":"2017-02-19T12:06:56-0800","dateStarted":"2017-02-19T12:15:59-0800","dateFinished":"2017-02-19T12:15:59-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7698","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>After training the CrossValidatorModel, <code>cvModel.bestModel</code> will contain a model trained on all of the training data using the best hyperparams.</p>\n<p>However, we could also train that &ldquo;best model&rdquo; ourselves:</p>\n</div>"}]}},{"text":"val lr = new LinearRegression().setRegParam(0.1).setElasticNetParam(0.7)\nval completePipeline = new Pipeline().setStages( ((indexers ++ encoders) :+ assembler :+ lr).toArray )\nval finalModel = completePipeline.fit(train)","user":"anonymous","dateUpdated":"2017-02-19T12:07:22-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534833683_1996689876","id":"20170219-120713_1880334707","dateCreated":"2017-02-19T12:07:13-0800","dateStarted":"2017-02-19T12:07:19-0800","dateFinished":"2017-02-19T12:07:23-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7699"},{"text":"%md Run the final model against the test set","user":"anonymous","dateUpdated":"2017-02-19T12:16:02-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534839675_-1254838403","id":"20170219-120719_85872729","dateCreated":"2017-02-19T12:07:19-0800","dateStarted":"2017-02-19T12:16:02-0800","dateFinished":"2017-02-19T12:16:02-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7700","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Run the final model against the test set</p>\n</div>"}]}},{"text":"val predictions = finalModel.transform(test).select('label, 'prediction)\nval eval = new RegressionEvaluator()\neval.evaluate(predictions)","user":"anonymous","dateUpdated":"2017-02-19T12:07:41-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534853027_708181133","id":"20170219-120733_197164508","dateCreated":"2017-02-19T12:07:33-0800","dateStarted":"2017-02-19T12:07:39-0800","dateFinished":"2017-02-19T12:07:40-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7701"},{"text":"%md We can examine the parameters of the final model:","user":"anonymous","dateUpdated":"2017-02-19T12:16:05-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534888561_102833196","id":"20170219-120808_499925378","dateCreated":"2017-02-19T12:08:08-0800","dateStarted":"2017-02-19T12:16:05-0800","dateFinished":"2017-02-19T12:16:05-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7702","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>We can examine the parameters of the final model:</p>\n</div>"}]}},{"text":"finalModel.stages.last.asInstanceOf[LinearRegressionModel].coefficients","user":"anonymous","dateUpdated":"2017-02-19T12:08:03-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534859067_1017149824","id":"20170219-120739_777219916","dateCreated":"2017-02-19T12:07:39-0800","dateStarted":"2017-02-19T12:08:03-0800","dateFinished":"2017-02-19T12:08:03-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7703"},{"text":"finalModel.stages.last.asInstanceOf[LinearRegressionModel].intercept","user":"anonymous","dateUpdated":"2017-02-19T12:09:03-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534883554_-1034869302","id":"20170219-120803_1553554723","dateCreated":"2017-02-19T12:08:03-0800","dateStarted":"2017-02-19T12:09:03-0800","dateFinished":"2017-02-19T12:09:03-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7704"},{"text":"%md One area where Spark ML really shines is in the pluggability of the different components. \nLet's swap in a Gradient Boosted Tree regressor and see if we can do better:","user":"anonymous","dateUpdated":"2017-02-19T12:16:08-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487534943234_-1044411403","id":"20170219-120903_508219683","dateCreated":"2017-02-19T12:09:03-0800","dateStarted":"2017-02-19T12:16:08-0800","dateFinished":"2017-02-19T12:16:08-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7705","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>One area where Spark ML really shines is in the pluggability of the different components.<br/>Let&rsquo;s swap in a Gradient Boosted Tree regressor and see if we can do better:</p>\n</div>"}]}},{"text":"val baseGBTPipeline = new Pipeline().setStages( ((indexers ++ encoders) :+ assembler :+ new GBTRegressor).toArray )\n\nval baseGBTPipelineModel = baseGBTPipeline.fit(train)","user":"anonymous","dateUpdated":"2017-02-19T12:13:24-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487535031455_-17361703","id":"20170219-121031_1700959407","dateCreated":"2017-02-19T12:10:31-0800","dateStarted":"2017-02-19T12:13:24-0800","dateFinished":"2017-02-19T12:13:35-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7706"},{"text":"eval.evaluate(baseGBTPipelineModel.transform(test))","user":"anonymous","dateUpdated":"2017-02-19T12:13:37-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487535130060_1134563577","id":"20170219-121210_699263768","dateCreated":"2017-02-19T12:12:10-0800","dateStarted":"2017-02-19T12:13:37-0800","dateFinished":"2017-02-19T12:13:37-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7707"},{"text":"%md Not surprisingly, we did significantly better with the GBT model. See if you can add tuning and crossvalidation,\nand improve the GBT model even further!","user":"anonymous","dateUpdated":"2017-02-19T12:16:11-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487535217115_227065160","id":"20170219-121337_1921596346","dateCreated":"2017-02-19T12:13:37-0800","dateStarted":"2017-02-19T12:16:11-0800","dateFinished":"2017-02-19T12:16:11-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7708","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Not surprisingly, we did significantly better with the GBT model. See if you can add tuning and crossvalidation,<br/>and improve the GBT model even further!</p>\n</div>"}]}},{"text":"%md\n","user":"anonymous","dateUpdated":"2017-02-19T12:14:33-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1487535273612_-1822030861","id":"20170219-121433_827534889","dateCreated":"2017-02-19T12:14:33-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7709"}],"name":"Spark Machine Learning","id":"2CANQG3YX","angularObjects":{"2CAVTNYXD:shared_process":[],"2C7K2429Q:shared_process":[],"2C8SPPQZU:shared_process":[],"2C7UX75H1:shared_process":[],"2C8CZHBMK:shared_process":[],"2C8M1YA6S:shared_process":[],"2C8HBGBZH:shared_process":[],"2C8W1YSQF:shared_process":[],"2CA11FFZW:shared_process":[],"2C8GTCYUP:shared_process":[],"2C7JSZ74W:shared_process":[],"2C7NXAQD7:shared_process":[],"2C8BUSWZY:shared_process":[],"2C8BMRSH6:shared_process":[],"2CAD4S1XP:shared_process":[],"2C8DQ16J7:shared_process":[],"2C9YA18WV:shared_process":[],"2CA315FYH:shared_process":[],"2C915WF4P:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}