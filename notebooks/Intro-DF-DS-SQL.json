{"paragraphs":[{"text":"%md # Apache Spark 2.1\n&copy;2016, 2017 by Adam Breindel. All Rights Reserved.","user":"anonymous","dateUpdated":"2017-02-07T14:39:30-0800","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Apache Spark 2.1</h1>\n<p>&copy;2016, 2017 by Adam Breindel. All Rights Reserved.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475251_-122285502","id":"20161126-102337_1246635846","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T14:39:30-0800","dateFinished":"2017-02-07T14:39:30-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:22893"},{"text":"%md #### Class Logistics and Operations\n* Start, End\n* Time for questions\n* Breaks","user":"anonymous","dateUpdated":"2017-02-18T15:37:14-0800","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Class Logistics and Operations</h4>\n<ul>\n  <li>Start, End</li>\n  <li>Time for questions</li>\n  <li>Breaks</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475258_-124978744","id":"20161126-102352_128347204","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-18T15:37:14-0800","dateFinished":"2017-02-18T15:37:14-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22894"},{"text":"%md #### Class Schedule\n* Background / Architecture\n* Querying Data with DataFrame, Dataset, SQL\n* RDDs, Memory, Job Execution\n* SQL/DataFrame/Dataset Execution\n* Classic (DStream) Streaming\n* Spark 2.x Structured Streaming\n* Machine Learning\n","user":"anonymous","dateUpdated":"2017-02-18T15:39:38-0800","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Class Schedule</h4>\n<ul>\n  <li>Background / Architecture</li>\n  <li>Querying Data with DataFrame, Dataset, SQL</li>\n  <li>RDDs, Memory, Job Execution</li>\n  <li>SQL/DataFrame/Dataset Execution</li>\n  <li>Classic (DStream) Streaming</li>\n  <li>Spark 2.x Structured Streaming</li>\n  <li>Machine Learning</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475259_-125363493","id":"20161126-102417_425406021","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-18T15:39:38-0800","dateFinished":"2017-02-18T15:39:38-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22895"},{"text":"%sh ls `pwd`/data","user":"anonymous","dateUpdated":"2017-02-07T11:14:45-0800","config":{"colWidth":12,"editorMode":"ace/mode/sh","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475261_-127671987","id":"20161126-102452_1680997678","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T11:14:45-0800","dateFinished":"2017-02-07T11:14:45-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22896"},{"text":"%sql SELECT * FROM parquet.`data/amazon20k.parquet`","user":"anonymous","dateUpdated":"2017-02-07T11:14:23-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"rating","index":0,"aggr":"sum"}],"values":[{"name":"review","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"rating","index":0,"aggr":"sum"},"yAxis":{"name":"review","index":1,"aggr":"sum"}}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475262_-126517740","id":"20161126-102619_1201322179","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T11:14:23-0800","dateFinished":"2017-02-07T11:14:25-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22897"},{"text":"%sql SELECT count(1), rating FROM parquet.`data/amazon20k.parquet` GROUP BY rating","user":"anonymous","dateUpdated":"2017-02-07T11:15:07-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"count(1)","index":0,"aggr":"sum"}],"values":[{"name":"rating","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"count(1)","index":0,"aggr":"sum"},"yAxis":{"name":"rating","index":1,"aggr":"sum"}}},"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475263_-126902489","id":"20161126-103452_1583981582","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T11:15:07-0800","dateFinished":"2017-02-07T11:15:08-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22898"},{"text":"%sql SELECT * FROM parquet.`data/amazon20k.parquet` WHERE rating = 1 AND review LIKE '%awesome%'\n\n-- What kind of SQL is this? Spark 2.0 supports the SQL:2003 standard as well as HiveQL.","user":"anonymous","dateUpdated":"2017-02-07T11:15:19-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475263_-126902489","id":"20161126-103554_1869614738","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T11:15:19-0800","dateFinished":"2017-02-07T11:15:19-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22899"},{"text":"%md #### Introduction\n* What is Spark?\n* How is Spark different from ... \n    * Hadoop?\n    * RDBMSs?","user":"anonymous","dateUpdated":"2017-02-07T14:39:39-0800","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Introduction</h4>\n<ul>\n  <li>What is Spark?</li>\n  <li>How is Spark different from &hellip;\n    <ul>\n      <li>Hadoop?</li>\n      <li>RDBMSs?</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475264_-436625353","id":"20161126-103633_1195718365","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T14:39:39-0800","dateFinished":"2017-02-07T14:39:39-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22900"},{"text":"%md #### Basic Architecture\n* Spark cluster / Spark application\n* Driver\n* Executors\n\n<img src=\"http://i.imgur.com/h621Rva.png\" width=600/>","user":"anonymous","dateUpdated":"2017-02-07T14:39:42-0800","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Basic Architecture</h4>\n<ul>\n  <li>Spark cluster / Spark application</li>\n  <li>Driver</li>\n  <li>Executors</li>\n</ul>\n<img src=\"http://i.imgur.com/h621Rva.png\" width=600/>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475265_-437010102","id":"20161126-103709_2126719124","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T14:39:42-0800","dateFinished":"2017-02-07T14:39:42-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22901"},{"text":"%md #### Spark application(s) vs. Underlying cluster\n* Spark *applications*, with their drivers and executors, are sometimes referred to as \"Spark Clusters\"\n  * __But__ that \"Spark Cluster\" is not normally a long-running thing\n  * One does not normally \"deploy machines (or VMs, or Containers) for a Spark cluster\" in the absence of a specific Spark application\n  \n* The underlying cluster -- most commonly YARN -- may have long-running nodes (hardware, VMs, etc.)\n  * *Multiple* Apache Spark application (\"Spark clusters\") can be launched in that cluster\n  * This pattern allows multiple users, teams, departments, etc. to run independent Spark applications on a common, shared infrastructure\n\n<img src=\"http://hortonworks.com/wp-content/uploads/2012/08/yarnflow1.png\" width=700>","user":"anonymous","dateUpdated":"2017-02-07T14:39:45-0800","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Spark application(s) vs. Underlying cluster</h4>\n<ul>\n  <li>Spark <em>applications</em>, with their drivers and executors, are sometimes referred to as &ldquo;Spark Clusters&rdquo;</li>\n  <li><strong>But</strong> that &ldquo;Spark Cluster&rdquo; is not normally a long-running thing</li>\n  <li>One does not normally &ldquo;deploy machines (or VMs, or Containers) for a Spark cluster&rdquo; in the absence of a specific Spark application</li>\n  <li>\n  <p>The underlying cluster &ndash; most commonly YARN &ndash; may have long-running nodes (hardware, VMs, etc.)</p></li>\n  <li><em>Multiple</em> Apache Spark application (&ldquo;Spark clusters&rdquo;) can be launched in that cluster</li>\n  <li>This pattern allows multiple users, teams, departments, etc. to run independent Spark applications on a common, shared infrastructure</li>\n</ul>\n<img src=\"http://hortonworks.com/wp-content/uploads/2012/08/yarnflow1.png\" width=700>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475265_-437010102","id":"20161126-103727_1993182767","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T14:39:45-0800","dateFinished":"2017-02-07T14:39:45-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22902"},{"text":"%md #### Programming Spark\n* Several ways\n  * Interactive (shell, notebooks)\n  * Scripts\n  * Compiled Programs\n* Languages\n  * SQL\n  * Scala\n  * Python\n  * R\n  * Java\n  * C#, F# (via Mobius)\n  * JavaScript (via Eclair)\n  * others\n  \nPrincipally: Scala, SQL, Python, R","user":"anonymous","dateUpdated":"2017-02-07T14:39:49-0800","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Programming Spark</h4>\n<ul>\n  <li>Several ways</li>\n  <li>Interactive (shell, notebooks)</li>\n  <li>Scripts</li>\n  <li>Compiled Programs</li>\n  <li>Languages</li>\n  <li>SQL</li>\n  <li>Scala</li>\n  <li>Python</li>\n  <li>R</li>\n  <li>Java</li>\n  <li>C#, F# (via Mobius)</li>\n  <li>JavaScript (via Eclair)</li>\n  <li>others</li>\n</ul>\n<p>Principally: Scala, SQL, Python, R</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475266_-435855855","id":"20161126-104129_1597159321","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T14:39:49-0800","dateFinished":"2017-02-07T14:39:49-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22903"},{"text":"%md #### Distributed Data Basics\n* Data-Parallel -> Partitions\n* Map operations (\"narrow\", similar to SQL SELECT expressions, e.g., squaring a number)\n* Reduce operations (\"wide\", ORDER BY / GROUP BY etc., e.g., sorting numbers)\n\n<img src=\"http://i.imgur.com/fmBGHd6.png\" width=700/>","user":"anonymous","dateUpdated":"2017-02-18T15:43:29-0800","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Distributed Data Basics</h4>\n<ul>\n  <li>Data-Parallel -&gt; Partitions</li>\n  <li>Map operations (&ldquo;narrow&rdquo;, similar to SQL SELECT expressions, e.g., squaring a number)</li>\n  <li>Reduce operations (&ldquo;wide&rdquo;, ORDER BY / GROUP BY etc., e.g., sorting numbers)</li>\n</ul>\n<img src=\"http://i.imgur.com/fmBGHd6.png\" width=700/>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475267_-436240604","id":"20161126-104450_418734759","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-18T15:43:29-0800","dateFinished":"2017-02-18T15:43:29-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22904"},{"text":"val path = \"data/pageviews-20170120-180000.gz\"\nspark.read.text(path).show","user":"anonymous","dateUpdated":"2017-02-13T22:18:06-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475269_-438549098","id":"20161126-104550_659427132","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-13T22:18:06-0800","dateFinished":"2017-02-13T22:18:06-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22905"},{"text":"val pc1 = spark.read.option(\"delimiter\",\" \").csv(path)\npc1.createOrReplaceTempView(\"pc1\")","user":"anonymous","dateUpdated":"2017-02-13T22:18:09-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475269_-437394851","id":"20161126-105136_1372281660","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-13T22:18:09-0800","dateFinished":"2017-02-13T22:18:09-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22906"},{"text":"%sql SELECT * FROM pc1","user":"anonymous","dateUpdated":"2017-02-07T12:52:26-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475270_-437394851","id":"20161126-105340_656589578","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:52:26-0800","dateFinished":"2017-02-07T12:52:26-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22907"},{"text":"val pc2 = pc1.withColumnRenamed(\"_c0\", \"project\").withColumnRenamed(\"_c1\", \"page\").withColumnRenamed(\"_c2\",\"requests\").drop(\"_c3\")\npc2.createOrReplaceTempView(\"pc2\")","user":"anonymous","dateUpdated":"2017-02-13T22:18:12-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475271_-437779600","id":"20161126-105550_1080715154","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-13T22:18:12-0800","dateFinished":"2017-02-13T22:18:12-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22908"},{"text":"%sql SELECT * FROM pc2","user":"anonymous","dateUpdated":"2017-02-07T12:52:34-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"project","index":0,"aggr":"sum"}],"values":[{"name":"page","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"project","index":0,"aggr":"sum"},"yAxis":{"name":"page","index":1,"aggr":"sum"}}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475271_-437779600","id":"20161126-105720_242040525","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:52:34-0800","dateFinished":"2017-02-07T12:52:34-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22909"},{"text":"spark.sql(\"SELECT * FROM pc2 WHERE requests is null\").show","user":"anonymous","dateUpdated":"2017-02-07T12:53:04-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475272_-439703344","id":"20161126-111348_1757979323","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:53:04-0800","dateFinished":"2017-02-07T12:53:14-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22910"},{"text":"import org.apache.spark.sql.functions._\n\nval pc3 = pc2.filter(! isnull('requests)).withColumn(\"req\",'requests cast \"bigint\").drop(\"requests\")\n\npc3.createOrReplaceTempView(\"pagecounts\")","user":"anonymous","dateUpdated":"2017-02-13T22:18:15-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475273_-440088093","id":"20161126-110502_713856540","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-13T22:18:15-0800","dateFinished":"2017-02-13T22:18:15-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22911"},{"text":"%sql DESCRIBE pagecounts","user":"anonymous","dateUpdated":"2017-02-07T12:53:35-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475273_-440088093","id":"20161126-112120_1782357803","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:53:35-0800","dateFinished":"2017-02-07T12:53:35-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22912"},{"text":"%sql SELECT * FROM pagecounts ORDER BY req DESC","user":"anonymous","dateUpdated":"2017-02-07T12:53:40-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"project","index":0,"aggr":"sum"}],"values":[{"name":"page","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"project","index":0,"aggr":"sum"},"yAxis":{"name":"page","index":1,"aggr":"sum"}}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475274_-438933847","id":"20161126-110440_349291315","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:53:40-0800","dateFinished":"2017-02-07T12:53:52-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22913"},{"text":"%sql SELECT * FROM pagecounts WHERE project = 'en' ORDER BY req DESC","user":"anonymous","dateUpdated":"2017-02-07T12:54:01-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475274_-438933847","id":"20161126-111008_1036680172","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:54:01-0800","dateFinished":"2017-02-07T12:54:11-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22914"},{"text":"%sql SELECT * FROM pagecounts WHERE project = 'en' AND lower(page) = 'san_francisco' ORDER BY req DESC","user":"anonymous","dateUpdated":"2017-02-07T12:54:43-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"project","index":0,"aggr":"sum"}],"values":[{"name":"page","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"project","index":0,"aggr":"sum"},"yAxis":{"name":"page","index":1,"aggr":"sum"}}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475275_-439318596","id":"20161126-111252_1668202516","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:54:43-0800","dateFinished":"2017-02-07T12:54:53-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22915"},{"text":"%sql SELECT count(*) FROM pagecounts","user":"anonymous","dateUpdated":"2017-02-07T12:56:22-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475275_-439318596","id":"20161126-112233_3160373","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:56:22-0800","dateFinished":"2017-02-07T12:56:30-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22916"},{"text":"%sql SELECT count(*) FROM pagecounts WHERE project = 'en'","user":"anonymous","dateUpdated":"2017-02-07T12:56:37-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475276_-441242340","id":"20161126-112012_407832390","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:56:37-0800","dateFinished":"2017-02-07T12:56:45-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22917"},{"text":"%sql SELECT COUNT(DISTINCT lower(page)) FROM pagecounts","user":"anonymous","dateUpdated":"2017-02-07T12:56:51-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475276_-441242340","id":"20161126-112214_896490928","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:56:51-0800","dateFinished":"2017-02-07T12:57:14-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22918"},{"text":"%sql SELECT * FROM pagecounts WHERE project = 'en' AND page LIKE '%Spark%' ORDER BY req DESC","user":"anonymous","dateUpdated":"2017-02-07T12:57:26-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475277_-441627089","id":"20161126-112433_1605987897","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:57:26-0800","dateFinished":"2017-02-07T12:57:36-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22919"},{"text":"%sql SELECT * FROM pagecounts WHERE project = 'en' AND page LIKE '%Apache%' ORDER BY req DESC","user":"anonymous","dateUpdated":"2017-02-07T12:57:48-0800","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475277_-441627089","id":"20161126-112834_2047173312","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:57:48-0800","dateFinished":"2017-02-07T12:57:57-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22920"},{"text":"%md We can write all kinds of SQL queries (SQL:2003 + HiveQL) ... and we can use a programmatic API or \"domain-specific language\" as well.\nThe DataFrame/Dataset API allows us to write native Python, Java, Scala, or R programs using Spark.\nCommon tasks are fairly similar across these APIs:\n\n|SQL|DataFame API|DataFrame example (with String column names)|\n|---|---|---|\n|SELECT|select, selectExpr|myDataFrame.select(\"someColumn\")|\n|WHERE|filter, where|myDataFrame.filter(\"someColumn > 10\")|\n|GROUP BY|groupBy|myDataFrame.groupBy(\"someColumn\")|\n|ORDER BY|orderBy|myDataFrame.orderBy(\"column\")|\n|JOIN|join|myDataFrame.join(otherDataFrame, \"innerEquiJoinColumn\")|\n|UNION|union|myDataFrame.union(otherDataFrame)|\n<br/>\n\nThe API support -- both for SQL and DataFrame/Dataset -- is far broader than these examples. E.g., columns and expressions can be written in a strongly-typed manner, using Column objects. These can be generated from Strings or Symbols; many types of JOIN are supported; and a variety of mechanisms for creating a DataFrame from a source exist in all of these APIs.","user":"anonymous","dateUpdated":"2017-02-07T14:39:58-0800","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>We can write all kinds of SQL queries (SQL:2003 + HiveQL) &hellip; and we can use a programmatic API or &ldquo;domain-specific language&rdquo; as well.<br/>The DataFrame/Dataset API allows us to write native Python, Java, Scala, or R programs using Spark.<br/>Common tasks are fairly similar across these APIs:</p>\n<table>\n  <thead>\n    <tr>\n      <th>SQL</th>\n      <th>DataFame API</th>\n      <th>DataFrame example (with String column names)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>SELECT</td>\n      <td>select, selectExpr</td>\n      <td>myDataFrame.select(&ldquo;someColumn&rdquo;)</td>\n    </tr>\n    <tr>\n      <td>WHERE</td>\n      <td>filter, where</td>\n      <td>myDataFrame.filter(&ldquo;someColumn &gt; 10&rdquo;)</td>\n    </tr>\n    <tr>\n      <td>GROUP BY</td>\n      <td>groupBy</td>\n      <td>myDataFrame.groupBy(&ldquo;someColumn&rdquo;)</td>\n    </tr>\n    <tr>\n      <td>ORDER BY</td>\n      <td>orderBy</td>\n      <td>myDataFrame.orderBy(&ldquo;column&rdquo;)</td>\n    </tr>\n    <tr>\n      <td>JOIN</td>\n      <td>join</td>\n      <td>myDataFrame.join(otherDataFrame, &ldquo;innerEquiJoinColumn&rdquo;)</td>\n    </tr>\n    <tr>\n      <td>UNION</td>\n      <td>union</td>\n      <td>myDataFrame.union(otherDataFrame)</td>\n    </tr>\n  </tbody>\n</table>\n<br/>\n<p>The API support &ndash; both for SQL and DataFrame/Dataset &ndash; is far broader than these examples. E.g., columns and expressions can be written in a strongly-typed manner, using Column objects. These can be generated from Strings or Symbols; many types of JOIN are supported; and a variety of mechanisms for creating a DataFrame from a source exist in all of these APIs.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475278_-440472842","id":"20161126-112853_1889717239","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T14:39:58-0800","dateFinished":"2017-02-07T14:39:58-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22921"},{"text":"// Here's the earlier query with the DataFrame/Dataset API:\n\nval query = spark.table(\"pagecounts\").filter(\"project = 'en'\").filter('page like \"%Spark%\").orderBy('req desc)\n\nquery.show","user":"anonymous","dateUpdated":"2017-02-07T12:58:35-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475278_-440472842","id":"20161126-113000_29682773","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:58:35-0800","dateFinished":"2017-02-07T12:58:45-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22922"},{"text":"// Let's take that apart:\n\nval query = spark.table(\"pagecounts\")","user":"anonymous","dateUpdated":"2017-02-07T12:58:53-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475279_-440857591","id":"20161126-113608_155390759","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:58:53-0800","dateFinished":"2017-02-07T12:58:53-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22923"},{"text":"query.show","user":"anonymous","dateUpdated":"2017-02-07T12:58:57-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475280_-430854120","id":"20161126-113644_1442933056","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:58:57-0800","dateFinished":"2017-02-07T12:58:57-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22924"},{"text":"val step1 = spark.table(\"pagecounts\")\n\nval step2 = step1.filter(\"project = 'en'\")\n\nstep2.show","user":"anonymous","dateUpdated":"2017-02-07T12:59:01-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475282_-429699873","id":"20161126-113657_142278497","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:59:01-0800","dateFinished":"2017-02-07T12:59:03-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22925"},{"text":"val step1 = spark.table(\"pagecounts\")\n\nval step2 = step1.filter(\"project = 'en'\")\n\nval step3 = step2.filter('page like \"%Spark%\") // what is 'page here? A Scala symbol that is converted to a column object in context\n\nstep3.show","user":"anonymous","dateUpdated":"2017-02-07T12:59:11-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475282_-429699873","id":"20161126-113709_132529865","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:59:11-0800","dateFinished":"2017-02-07T12:59:14-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22926"},{"text":"//Show me this \"page\" column object\n\nval theDataFrame = spark.table(\"pagecounts\")\n\nval theColumn = theDataFrame(\"page\")","user":"anonymous","dateUpdated":"2017-02-07T12:59:20-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475283_-430084622","id":"20161126-113744_1879862133","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:59:20-0800","dateFinished":"2017-02-07T12:59:20-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22927"},{"text":"// So what is 'page like \"%Spark%\"? An API call on Column, that returns another Column:\n\ntheColumn.like(\"%Spark%\") // Java-style syntax, same call","user":"anonymous","dateUpdated":"2017-02-07T12:59:24-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475283_-430084622","id":"20161126-113803_314269505","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T12:59:24-0800","dateFinished":"2017-02-07T12:59:24-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22928"},{"text":"%md #### Where do these API docs live?\n1. Dataset class (DataFrame is a limited but very useful form of Dataset ... it is a Dataset[Row])\n2. Column\n3. RelationalGroupedDataset and KeyValueGroupedDataset\n4. *tons* of helpful functions in org.apache.spark.sql.functions (package object) http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$","user":"anonymous","dateUpdated":"2017-02-07T14:40:12-0800","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Where do these API docs live?</h4>\n<ol>\n  <li>Dataset class (DataFrame is a limited but very useful form of Dataset &hellip; it is a Dataset[Row])</li>\n  <li>Column</li>\n  <li>RelationalGroupedDataset and KeyValueGroupedDataset</li>\n  <li><em>tons</em> of helpful functions in org.apache.spark.sql.functions (package object) <a href=\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\">http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$</a></li>\n</ol>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475284_-432008366","id":"20161126-113810_2053873340","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T14:40:12-0800","dateFinished":"2017-02-07T14:40:12-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22929"},{"text":"spark.table(\"pagecounts\").groupBy(\"project\").count().orderBy('count desc).show","user":"anonymous","dateUpdated":"2017-02-07T13:40:47-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486494475285_-432393115","id":"20161126-113828_659084819","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T13:40:47-0800","dateFinished":"2017-02-07T13:40:57-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22930"},{"text":"%md #### Hopefully that seemed reasonable ... \n\n__but__ ... it's taking too long!\n\n* ... turns out our Spark code is fine in terms of API ... but the execution underneath isn't quite right yet.\n\nHow is that possible? We've barely even done anything yet and something is wrong?\n\n* How would we even know? How can we fix it? \n\nLet's figure it out:","user":"anonymous","dateUpdated":"2017-02-07T14:40:16-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Hopefully that seemed reasonable &hellip;</h4>\n<p><strong>but</strong> &hellip; it&rsquo;s taking too long!</p>\n<ul>\n  <li>&hellip; turns out our Spark code is fine in terms of API &hellip; but the execution underneath isn&rsquo;t quite right yet.</li>\n</ul>\n<p>How is that possible? We&rsquo;ve barely even done anything yet and something is wrong?</p>\n<ul>\n  <li>How would we even know? How can we fix it?</li>\n</ul>\n<p>Let&rsquo;s figure it out:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486494475285_-432393115","id":"20161126-113859_398212253","dateCreated":"2017-02-07T11:07:55-0800","dateStarted":"2017-02-07T14:40:16-0800","dateFinished":"2017-02-07T14:40:16-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22931"},{"text":"%md #### Spark is a parallel cluster computing tool...\n\nso we're using lots of nodes or at least threads, right?\n\nTake a look at the parallelism in that last query. In fact, we're only using 1 thread.\n\nWe'll talk about why, and about how to fix it, but first, let's get some more terminology on the table\n\n* Application\n* Query\n* Job\n* Stage\n* Task\n\nNow we can at least use the Spark Graphical UI to see that we did all of that work with just one thread!","user":"anonymous","dateUpdated":"2017-02-07T14:40:27-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Spark is a parallel cluster computing tool&hellip;</h4>\n<p>so we&rsquo;re using lots of nodes or at least threads, right?</p>\n<p>Take a look at the parallelism in that last query. In fact, we&rsquo;re only using 1 thread.</p>\n<p>We&rsquo;ll talk about why, and about how to fix it, but first, let&rsquo;s get some more terminology on the table</p>\n<ul>\n  <li>Application</li>\n  <li>Query</li>\n  <li>Job</li>\n  <li>Stage</li>\n  <li>Task</li>\n</ul>\n<p>Now we can at least use the Spark Graphical UI to see that we did all of that work with just one thread!</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501293938_-979309971","id":"20170207-130133_373843682","dateCreated":"2017-02-07T13:01:33-0800","dateStarted":"2017-02-07T14:40:27-0800","dateFinished":"2017-02-07T14:40:27-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22932"},{"text":"%md What was the problem? Let's think about how the data is stored:\n","user":"anonymous","dateUpdated":"2017-02-07T14:40:30-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>What was the problem? Let&rsquo;s think about how the data is stored:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501331237_-849772185","id":"20170207-130211_30685392","dateCreated":"2017-02-07T13:02:11-0800","dateStarted":"2017-02-07T14:40:30-0800","dateFinished":"2017-02-07T14:40:30-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22933"},{"text":"%sh ls -la data\n","user":"anonymous","dateUpdated":"2017-02-07T13:04:04-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501365928_165241386","id":"20170207-130245_366214547","dateCreated":"2017-02-07T13:02:45-0800","dateStarted":"2017-02-07T13:04:04-0800","dateFinished":"2017-02-07T13:04:04-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22934"},{"text":"%md That's just the .gzip file we uploaded! So that's pretty straightforward ... \n\nHowever, gzip is not a *splittable* compression format. So Spark can't read different pieces of it in parallel using different tasks.\n\nOther things being equal, parquet is a the default recommended file format. It is a columnar, compressed file format based on the Google's Dremel paper, and it generally provides great performance on Spark, Impala, Presto and other data tools. It even supports partitioning based on the contents, so that queries don't need to process the entire dataset to find the data they are looking for.\n\nSo let's convert this to parquet. How? Probably the easiest way is tell Spark to do it for us:","user":"anonymous","dateUpdated":"2017-02-07T14:40:33-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>That&rsquo;s just the .gzip file we uploaded! So that&rsquo;s pretty straightforward &hellip; </p>\n<p>However, gzip is not a <em>splittable</em> compression format. So Spark can&rsquo;t read different pieces of it in parallel using different tasks.</p>\n<p>Other things being equal, parquet is a the default recommended file format. It is a columnar, compressed file format based on the Google&rsquo;s Dremel paper, and it generally provides great performance on Spark, Impala, Presto and other data tools. It even supports partitioning based on the contents, so that queries don&rsquo;t need to process the entire dataset to find the data they are looking for.</p>\n<p>So let&rsquo;s convert this to parquet. How? Probably the easiest way is tell Spark to do it for us:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501376354_2124782859","id":"20170207-130256_1864005968","dateCreated":"2017-02-07T13:02:56-0800","dateStarted":"2017-02-07T14:40:33-0800","dateFinished":"2017-02-07T14:40:33-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22935"},{"text":"spark.table(\"pagecounts\") // here is the table","user":"anonymous","dateUpdated":"2017-02-07T13:05:33-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501504557_-1087334111","id":"20170207-130504_718729059","dateCreated":"2017-02-07T13:05:04-0800","dateStarted":"2017-02-07T13:05:28-0800","dateFinished":"2017-02-07T13:05:28-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22936"},{"text":"spark.table(\"pagecounts\").write.parquet(\"data/pagecounts\")","user":"anonymous","dateUpdated":"2017-02-13T22:21:43-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1486501528827_1462258932","id":"20170207-130528_46718491","dateCreated":"2017-02-07T13:05:28-0800","dateStarted":"2017-02-13T22:21:43-0800","dateFinished":"2017-02-13T22:22:00-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22937"},{"text":"%md That takes a while ... remember we have to process it in one thread","user":"anonymous","dateUpdated":"2017-02-07T14:40:37-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>That takes a while &hellip; remember we have to process it in one thread</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501563578_-1742284008","id":"20170207-130603_378621249","dateCreated":"2017-02-07T13:06:03-0800","dateStarted":"2017-02-07T14:40:37-0800","dateFinished":"2017-02-07T14:40:37-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22938"},{"text":"%sh ls -la data/pagecounts\n","user":"anonymous","dateUpdated":"2017-02-07T13:06:47-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501577663_-1060277450","id":"20170207-130617_1177079965","dateCreated":"2017-02-07T13:06:17-0800","dateStarted":"2017-02-07T13:06:47-0800","dateFinished":"2017-02-07T13:06:47-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22939"},{"text":"spark.read.parquet(\"data/pagecounts\").count\n","user":"anonymous","dateUpdated":"2017-02-13T22:22:27-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501588776_422560135","id":"20170207-130628_1267566075","dateCreated":"2017-02-07T13:06:28-0800","dateStarted":"2017-02-13T22:22:27-0800","dateFinished":"2017-02-13T22:22:28-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22940"},{"text":"%md But now it's much faster\n\nNotice:\n\n* 2 Jobs\n* Reading is done in parallel \n  * How is the parallelism determined?\n    * With SparkSQL in 2.x see https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/DataSourceScanExec.scala\n    * Main number comes from defaultParallelism which is usually the total number of cores available    \n* Aggregation is required","user":"anonymous","dateUpdated":"2017-02-07T14:40:40-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>But now it&rsquo;s much faster</p>\n<p>Notice:</p>\n<ul>\n  <li>2 Jobs</li>\n  <li>Reading is done in parallel</li>\n  <li>How is the parallelism determined?\n    <ul>\n      <li>With SparkSQL in 2.x see <a href=\"https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/DataSourceScanExec.scala\">https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/DataSourceScanExec.scala</a></li>\n      <li>Main number comes from defaultParallelism which is usually the total number of cores available</li>\n    </ul>\n  </li>\n  <li>Aggregation is required</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501641853_148295466","id":"20170207-130721_1773043977","dateCreated":"2017-02-07T13:07:21-0800","dateStarted":"2017-02-07T14:40:40-0800","dateFinished":"2017-02-07T14:40:40-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22941"},{"text":"%md <img src=\"http://i.imgur.com/Uqo6FJM.png\" width=\"600\"/>","user":"anonymous","dateUpdated":"2017-02-07T14:40:43-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src=\"http://i.imgur.com/Uqo6FJM.png\" width=\"600\"/>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501662478_1022307050","id":"20170207-130742_262212438","dateCreated":"2017-02-07T13:07:42-0800","dateStarted":"2017-02-07T14:40:43-0800","dateFinished":"2017-02-07T14:40:43-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22942"},{"text":"spark.read.parquet(\"data/pagecounts\").filter(\"project = 'en'\").count\n\n// equivalently, with Column expression syntax: spark.read.parquet(\"/FileStore/pagecounts\").filter('project===\"en\").count\n","user":"anonymous","dateUpdated":"2017-02-07T13:09:50-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501718549_-227898658","id":"20170207-130838_1934126321","dateCreated":"2017-02-07T13:08:38-0800","dateStarted":"2017-02-07T13:09:46-0800","dateFinished":"2017-02-07T13:09:46-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22943"},{"text":"%md Notice that adding a filter step did not add any tasks (or stages, jobs, etc.). \n\nThis -- inlining of \"map\" operations into tasks -- is called pipelining and is a key part of the Spark architecture. We'll talk more about that tomorrow.\n\nThe filter does take more time than a simple count though.\n\nNotice that we're reading a file source and using Scala ... how do we get back to tables and SQL?","user":"anonymous","dateUpdated":"2017-02-07T14:40:46-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Notice that adding a filter step did not add any tasks (or stages, jobs, etc.). </p>\n<p>This &ndash; inlining of &ldquo;map&rdquo; operations into tasks &ndash; is called pipelining and is a key part of the Spark architecture. We&rsquo;ll talk more about that tomorrow.</p>\n<p>The filter does take more time than a simple count though.</p>\n<p>Notice that we&rsquo;re reading a file source and using Scala &hellip; how do we get back to tables and SQL?</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501772639_-508704058","id":"20170207-130932_1372993531","dateCreated":"2017-02-07T13:09:32-0800","dateStarted":"2017-02-07T14:40:46-0800","dateFinished":"2017-02-07T14:40:46-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22944"},{"text":"spark.read.parquet(\"data/pagecounts\").filter('project===\"en\").createOrReplaceTempView(\"pc\")","user":"anonymous","dateUpdated":"2017-02-07T13:11:35-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501844861_-2028337975","id":"20170207-131044_2097931105","dateCreated":"2017-02-07T13:10:44-0800","dateStarted":"2017-02-07T13:11:32-0800","dateFinished":"2017-02-07T13:11:33-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22945"},{"text":"%md Now we can try out all sort of interesting SQL queries...","user":"anonymous","dateUpdated":"2017-02-07T14:40:49-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now we can try out all sort of interesting SQL queries&hellip;</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501870925_-1902879186","id":"20170207-131110_81488512","dateCreated":"2017-02-07T13:11:10-0800","dateStarted":"2017-02-07T14:40:49-0800","dateFinished":"2017-02-07T14:40:49-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22946"},{"text":"// try it here!\n","user":"anonymous","dateUpdated":"2017-02-07T13:12:17-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501918403_-1477838920","id":"20170207-131158_1834219969","dateCreated":"2017-02-07T13:11:58-0800","dateStarted":"2017-02-07T13:12:17-0800","dateFinished":"2017-02-07T13:12:17-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22947"},{"text":"%md How about this one ...","user":"anonymous","dateUpdated":"2017-02-07T14:40:52-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>How about this one &hellip;</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501937564_1090790709","id":"20170207-131217_1040751492","dateCreated":"2017-02-07T13:12:17-0800","dateStarted":"2017-02-07T14:40:52-0800","dateFinished":"2017-02-07T14:40:52-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22948"},{"text":"%sql SELECT * FROM pc WHERE page = 'New_York'","user":"anonymous","dateUpdated":"2017-02-07T13:12:48-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":true},"editorMode":"ace/mode/sql","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501948699_-1714413521","id":"20170207-131228_1617197753","dateCreated":"2017-02-07T13:12:28-0800","dateStarted":"2017-02-07T13:12:43-0800","dateFinished":"2017-02-07T13:12:45-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22949"},{"text":"%md That took a while. How would we speed this sort of query up in a RDBMS, or with Hive?\n\nSpark does not support indices, so this flavor of query -- matching a very small fraction of records -- is not where Spark's performance shines.","user":"anonymous","dateUpdated":"2017-02-07T14:40:55-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>That took a while. How would we speed this sort of query up in a RDBMS, or with Hive?</p>\n<p>Spark does not support indices, so this flavor of query &ndash; matching a very small fraction of records &ndash; is not where Spark&rsquo;s performance shines.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501963587_-440864014","id":"20170207-131243_1098615335","dateCreated":"2017-02-07T13:12:43-0800","dateStarted":"2017-02-07T14:40:55-0800","dateFinished":"2017-02-07T14:40:55-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22950"},{"text":"%md #### Let's try to join our pageview data with some geography data and see whether big cities get searched more than small ones","user":"anonymous","dateUpdated":"2017-02-07T14:40:58-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Let&rsquo;s try to join our pageview data with some geography data and see whether big cities get searched more than small ones</h4>\n</div>"}]},"apps":[],"jobName":"paragraph_1486501983361_-1667661335","id":"20170207-131303_1181399912","dateCreated":"2017-02-07T13:13:03-0800","dateStarted":"2017-02-07T14:40:58-0800","dateFinished":"2017-02-07T14:40:58-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22951"},{"text":"spark.read.json(\"data/zips.json\").withColumnRenamed(\"_id\", \"zip\").createOrReplaceTempView(\"zip\")","user":"anonymous","dateUpdated":"2017-02-07T13:15:24-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486501997490_121066950","id":"20170207-131317_1452180989","dateCreated":"2017-02-07T13:13:17-0800","dateStarted":"2017-02-07T13:15:24-0800","dateFinished":"2017-02-07T13:15:24-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22952"},{"text":"%sql SELECT * FROM zip","user":"anonymous","dateUpdated":"2017-02-07T13:15:35-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486502039299_-5638031","id":"20170207-131359_1298502257","dateCreated":"2017-02-07T13:13:59-0800","dateStarted":"2017-02-07T13:15:35-0800","dateFinished":"2017-02-07T13:15:35-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22953"},{"text":"spark.table(\"zip\").schema","user":"anonymous","dateUpdated":"2017-02-07T13:15:53-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486502135320_-1166856184","id":"20170207-131535_1274807329","dateCreated":"2017-02-07T13:15:35-0800","dateStarted":"2017-02-07T13:15:53-0800","dateFinished":"2017-02-07T13:15:53-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22954"},{"text":"%sql SELECT page, pop, req FROM pc JOIN zip ON pc.page = zip.city ORDER BY req DESC","user":"anonymous","dateUpdated":"2017-02-07T13:16:41-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486502153355_-2147181058","id":"20170207-131553_394229149","dateCreated":"2017-02-07T13:15:53-0800","dateStarted":"2017-02-07T13:16:41-0800","dateFinished":"2017-02-07T13:16:42-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22955"},{"text":"%md That works ... but ... business logic fail! New\\_York (in Wikipedia) won't match NEW YORK in the zips dataset.\n\nLet's see if there are some built-in funtions that might help:","user":"anonymous","dateUpdated":"2017-02-07T14:41:01-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>That works &hellip; but &hellip; business logic fail! New_York (in Wikipedia) won&rsquo;t match NEW YORK in the zips dataset.</p>\n<p>Let&rsquo;s see if there are some built-in funtions that might help:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486502171541_119606220","id":"20170207-131611_1993650800","dateCreated":"2017-02-07T13:16:11-0800","dateStarted":"2017-02-07T14:41:01-0800","dateFinished":"2017-02-07T14:41:01-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22956"},{"text":"%sql SHOW FUNCTIONS","user":"anonymous","dateUpdated":"2017-02-07T14:41:11-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":true},"editorMode":"ace/mode/sql","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486502243884_-1075737449","id":"20170207-131723_1112504620","dateCreated":"2017-02-07T13:17:23-0800","dateStarted":"2017-02-07T14:41:04-0800","dateFinished":"2017-02-07T14:41:04-0800","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22957"},{"text":"%sql SELECT split(page, '_') FROM pc WHERE page LIKE 'New_%'","user":"anonymous","dateUpdated":"2017-02-07T13:33:27-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486502262607_2085005414","id":"20170207-131742_251786459","dateCreated":"2017-02-07T13:17:42-0800","dateStarted":"2017-02-07T13:33:27-0800","dateFinished":"2017-02-07T13:33:28-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22958"},{"text":"%md We *could* make our own functions if needed as well:","user":"anonymous","dateUpdated":"2017-02-07T14:41:21-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>We <em>could</em> make our own functions if needed as well:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486503201871_1783912302","id":"20170207-133321_163042577","dateCreated":"2017-02-07T13:33:21-0800","dateStarted":"2017-02-07T14:41:21-0800","dateFinished":"2017-02-07T14:41:21-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22959"},{"text":"val isOdd = spark.udf.register(\"isOdd\", (n:Long) => n%2 == 1 )","user":"anonymous","dateUpdated":"2017-02-07T13:34:23-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503243573_2016947542","id":"20170207-133403_1609265881","dateCreated":"2017-02-07T13:34:03-0800","dateStarted":"2017-02-07T13:34:20-0800","dateFinished":"2017-02-07T13:34:20-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22960"},{"text":"val someNumbers = spark.range(20)\n\nsomeNumbers.select('id, isOdd('id)).show","user":"anonymous","dateUpdated":"2017-02-07T13:34:41-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503260037_63592700","id":"20170207-133420_1902642726","dateCreated":"2017-02-07T13:34:20-0800","dateStarted":"2017-02-07T13:34:41-0800","dateFinished":"2017-02-07T13:34:41-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22961"},{"text":"someNumbers.createOrReplaceTempView(\"some_numbers\")\n\nspark.sql(\"SELECT id, isOdd(id) as odd FROM some_numbers\").show\n","user":"anonymous","dateUpdated":"2017-02-07T13:35:13-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503281115_-1406932396","id":"20170207-133441_912027593","dateCreated":"2017-02-07T13:34:41-0800","dateStarted":"2017-02-07T13:35:13-0800","dateFinished":"2017-02-07T13:35:14-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22962"},{"text":"%md Ok, back to our report about Wikipedia requests for large cities:","user":"anonymous","dateUpdated":"2017-02-07T14:41:27-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Ok, back to our report about Wikipedia requests for large cities:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486503313160_-530828502","id":"20170207-133513_1397643367","dateCreated":"2017-02-07T13:35:13-0800","dateStarted":"2017-02-07T14:41:27-0800","dateFinished":"2017-02-07T14:41:27-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22963"},{"text":"%sql SELECT city, state, sum(pop), sum(req) FROM pc \n        JOIN zip \n        ON lower(pc.page) = regexp_replace(lower(zip.city), ' ', '_') \n        WHERE city LIKE 'NEW %'\n        GROUP BY city, state \n        ORDER BY sum(req) DESC","user":"anonymous","dateUpdated":"2017-02-07T13:37:04-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":true},"editorMode":"ace/mode/sql","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503328897_1905816930","id":"20170207-133528_1215983145","dateCreated":"2017-02-07T13:35:28-0800","dateStarted":"2017-02-07T13:37:00-0800","dateFinished":"2017-02-07T13:37:02-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22964"},{"text":"%md That looks plausible ... how about all of the cities?","user":"anonymous","dateUpdated":"2017-02-07T14:41:30-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>That looks plausible &hellip; how about all of the cities?</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486503337804_-1422645805","id":"20170207-133537_23359214","dateCreated":"2017-02-07T13:35:37-0800","dateStarted":"2017-02-07T14:41:30-0800","dateFinished":"2017-02-07T14:41:30-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22965"},{"text":"%sql SELECT city, state, sum(pop), sum(req) FROM pc \n        JOIN zip ON lower(pc.page) = regexp_replace(lower(zip.city), ' ', '_') \n        GROUP BY city, state\n        ORDER BY sum(req) DESC","user":"anonymous","dateUpdated":"2017-02-07T14:41:37-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":true},"editorMode":"ace/mode/sql","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503440319_1120345211","id":"20170207-133720_1463467873","dateCreated":"2017-02-07T13:37:20-0800","dateStarted":"2017-02-07T14:41:33-0800","dateFinished":"2017-02-07T14:41:34-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22966"},{"text":"%md Something fishy is going on though: look at San Francisco's population ... that's way too high.\n\n__Exercise__: Can you find the real population data in the zip table, and figure out what's going wrong?","user":"anonymous","dateUpdated":"2017-02-07T14:41:48-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Something fishy is going on though: look at San Francisco&rsquo;s population &hellip; that&rsquo;s way too high.</p>\n<p><strong>Exercise</strong>: Can you find the real population data in the zip table, and figure out what&rsquo;s going wrong?</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486503469801_875306134","id":"20170207-133749_987406676","dateCreated":"2017-02-07T13:37:49-0800","dateStarted":"2017-02-07T14:41:48-0800","dateFinished":"2017-02-07T14:41:48-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22967"},{"text":"%sql SELECT * FROM pc WHERE lower(page) = 'san_francisco'\n","user":"anonymous","dateUpdated":"2017-02-07T13:40:05-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":true},"editorMode":"ace/mode/sql","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503559864_-1479651583","id":"20170207-133919_531560316","dateCreated":"2017-02-07T13:39:19-0800","dateStarted":"2017-02-07T13:39:35-0800","dateFinished":"2017-02-07T13:39:37-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22968"},{"text":"%md Let's learn to find and fix another potential problem. First, let's cache the data we're going to query.\nThis will let us look at caching and storage in the UI.","user":"anonymous","dateUpdated":"2017-02-07T14:41:50-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Let&rsquo;s learn to find and fix another potential problem. First, let&rsquo;s cache the data we&rsquo;re going to query.<br/>This will let us look at caching and storage in the UI.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486503568941_-787857736","id":"20170207-133928_1773109700","dateCreated":"2017-02-07T13:39:28-0800","dateStarted":"2017-02-07T14:41:50-0800","dateFinished":"2017-02-07T14:41:50-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22969"},{"text":"%sql CACHE TABLE pc","user":"anonymous","dateUpdated":"2017-02-07T13:43:51-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503610334_-334361377","id":"20170207-134010_962193397","dateCreated":"2017-02-07T13:40:10-0800","dateStarted":"2017-02-07T13:43:51-0800","dateFinished":"2017-02-07T13:43:53-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22970"},{"text":"%md Notes about caching...\n\n* This SQL call is the only caching API that processes the data right away. Spark is designed to operate on data lazily, and all of the other caching/persistence calls (e.g., Python, Scala, etc.) are lazy\n* How much space does this data set take up? How much is available? Take a look in UI. We'll talk more about memory and sizing later too.\n    * Something fishy is going on there ... can you figure out what it is? If not, we'll come back to that in just a minute","user":"anonymous","dateUpdated":"2017-02-07T14:42:08-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Notes about caching&hellip;</p>\n<ul>\n  <li>This SQL call is the only caching API that processes the data right away. Spark is designed to operate on data lazily, and all of the other caching/persistence calls (e.g., Python, Scala, etc.) are lazy</li>\n  <li>How much space does this data set take up? How much is available? Take a look in UI. We&rsquo;ll talk more about memory and sizing later too.\n    <ul>\n      <li>Something fishy is going on there &hellip; can you figure out what it is? If not, we&rsquo;ll come back to that in just a minute</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1486503886867_348566277","id":"20170207-134446_1731111853","dateCreated":"2017-02-07T13:44:46-0800","dateStarted":"2017-02-07T14:42:08-0800","dateFinished":"2017-02-07T14:42:08-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22971"},{"text":"%sql SELECT * FROM pc WHERE page LIKE 'Apache_%' ORDER BY req DESC","user":"anonymous","dateUpdated":"2017-02-07T13:44:31-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503825640_-1812876423","id":"20170207-134345_2017756943","dateCreated":"2017-02-07T13:43:45-0800","dateStarted":"2017-02-07T13:44:31-0800","dateFinished":"2017-02-07T13:44:32-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22972"},{"text":"%md That seems quick enough, but its actually running too slow. What do I mean by too slow? I mean we're not using all our horsepower to process this query.\n\nLet's look in the UI and see...\n\nIt's even more prominent if we retrieve all the data (we know our show and display calls do not show all the data ... but they do not sort all the data either!)","user":"anonymous","dateUpdated":"2017-02-07T14:42:11-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>That seems quick enough, but its actually running too slow. What do I mean by too slow? I mean we&rsquo;re not using all our horsepower to process this query.</p>\n<p>Let&rsquo;s look in the UI and see&hellip;</p>\n<p>It&rsquo;s even more prominent if we retrieve all the data (we know our show and display calls do not show all the data &hellip; but they do not sort all the data either!)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486503862591_-1889380158","id":"20170207-134422_855710643","dateCreated":"2017-02-07T13:44:22-0800","dateStarted":"2017-02-07T14:42:11-0800","dateFinished":"2017-02-07T14:42:11-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22973"},{"text":"spark.sql(\"SELECT * FROM pc WHERE page LIKE 'Apache_%' ORDER BY req DESC\").collect","user":"anonymous","dateUpdated":"2017-02-07T14:42:19-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486503973162_-561826242","id":"20170207-134613_1671710297","dateCreated":"2017-02-07T13:46:13-0800","dateStarted":"2017-02-07T14:42:14-0800","dateFinished":"2017-02-07T14:42:15-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22974"},{"text":"%md Recall the layout of the original file:","user":"anonymous","dateUpdated":"2017-02-07T14:42:23-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Recall the layout of the original file:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486503991055_1143796281","id":"20170207-134631_90988305","dateCreated":"2017-02-07T13:46:31-0800","dateStarted":"2017-02-07T14:42:23-0800","dateFinished":"2017-02-07T14:42:23-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22975"},{"text":"spark.read.text(\"data/pageviews-20170120-180000.gz\").show(false)","user":"anonymous","dateUpdated":"2017-02-07T14:42:30-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486504062738_955192699","id":"20170207-134742_857905117","dateCreated":"2017-02-07T13:47:42-0800","dateStarted":"2017-02-07T14:42:25-0800","dateFinished":"2017-02-07T14:42:26-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22976"},{"text":"%md Can you see what's going wrong here? We've induced skew because our query is focused on data that occurs in one small part of the dataset.\n \nOne way to fix this is to round-robin repartition:","user":"anonymous","dateUpdated":"2017-02-07T14:42:36-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Can you see what&rsquo;s going wrong here? We&rsquo;ve induced skew because our query is focused on data that occurs in one small part of the dataset.</p>\n<p>One way to fix this is to round-robin repartition:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486504090865_809555111","id":"20170207-134810_750350490","dateCreated":"2017-02-07T13:48:10-0800","dateStarted":"2017-02-07T14:42:36-0800","dateFinished":"2017-02-07T14:42:36-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22977"},{"text":"spark.table(\"pc\").repartition(32).createOrReplaceTempView(\"pcroundrobin\")\n\nspark.sql(\"CACHE TABLE pcroundrobin\")","user":"anonymous","dateUpdated":"2017-02-07T13:51:08-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486504119492_-483924718","id":"20170207-134839_1855992087","dateCreated":"2017-02-07T13:48:39-0800","dateStarted":"2017-02-07T13:50:48-0800","dateFinished":"2017-02-07T13:50:50-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22978"},{"text":"%md Compare the two DataFrames in the storage UI tab. Then run the following query and look at the task size distribution.","user":"anonymous","dateUpdated":"2017-02-07T14:42:39-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Compare the two DataFrames in the storage UI tab. Then run the following query and look at the task size distribution.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486504199719_-883924013","id":"20170207-134959_690506831","dateCreated":"2017-02-07T13:49:59-0800","dateStarted":"2017-02-07T14:42:39-0800","dateFinished":"2017-02-07T14:42:39-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22979"},{"text":"spark.sql(\"SELECT * FROM pcroundrobin WHERE page LIKE 'Apache_%' ORDER BY req DESC\").collect","user":"anonymous","dateUpdated":"2017-02-07T13:52:58-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486504264455_-934033315","id":"20170207-135104_253901682","dateCreated":"2017-02-07T13:51:04-0800","dateStarted":"2017-02-07T13:52:55-0800","dateFinished":"2017-02-07T13:52:55-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22980"},{"text":"%md We can also look at rows -- including just parts of rows, or rows with embedded data structures! -- as a Scala type.\n\nWhy? Sometimes we need to call our existing custom business logic (perhaps Java) or it's easier to express a query or aggregation in code:","user":"anonymous","dateUpdated":"2017-02-07T14:42:42-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>We can also look at rows &ndash; including just parts of rows, or rows with embedded data structures! &ndash; as a Scala type.</p>\n<p>Why? Sometimes we need to call our existing custom business logic (perhaps Java) or it&rsquo;s easier to express a query or aggregation in code:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486504366865_-61320997","id":"20170207-135246_704632782","dateCreated":"2017-02-07T13:52:46-0800","dateStarted":"2017-02-07T14:42:42-0800","dateFinished":"2017-02-07T14:42:42-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22981"},{"text":"case class Zip(city:String)\n\nspark.table(\"zip\").as[Zip].filter(item => {\n  val partsOfCityName = item.city.split(\" \")\n  partsOfCityName.size > 1 && (partsOfCityName contains \"NEW\") && partsOfCityName(0) != \"NEW\"\n}).show(false)","user":"anonymous","dateUpdated":"2017-02-07T13:54:36-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486504424276_-1785103339","id":"20170207-135344_1526646553","dateCreated":"2017-02-07T13:53:44-0800","dateStarted":"2017-02-07T13:54:32-0800","dateFinished":"2017-02-07T13:54:33-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22982"},{"text":"case class Zip(city:String, pop:Long)\nspark.table(\"zip\").as[Zip].filter('city === \"NEW YORK\").map(_.pop).reduce( (z1, z2) => z1 + z2 )","user":"anonymous","dateUpdated":"2017-02-07T13:55:22-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486504441567_55181299","id":"20170207-135401_476397975","dateCreated":"2017-02-07T13:54:01-0800","dateStarted":"2017-02-07T13:55:22-0800","dateFinished":"2017-02-07T13:55:23-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22983"},{"text":"case class Zip(city:String, state:String, zip:String)\nspark.table(\"zip\")\n    .filter(\"state = 'CT'\")\n    .as[Zip].groupByKey( z => (z.city, z.state)).reduceGroups( (z1, z2) => Zip(z1.city, z1.state, z1.zip + \" \" + z2.zip) )\n    .show(false)","user":"anonymous","dateUpdated":"2017-02-07T14:16:47-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486504522691_-2017537647","id":"20170207-135522_821054545","dateCreated":"2017-02-07T13:55:22-0800","dateStarted":"2017-02-07T14:16:47-0800","dateFinished":"2017-02-07T14:16:48-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22984"},{"text":"%md Spark also supports more complex queries, like pivoting dataframes and SQL WINDOW functions\n\nSee, e.g., https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html","user":"anonymous","dateUpdated":"2017-02-07T14:42:46-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Spark also supports more complex queries, like pivoting dataframes and SQL WINDOW functions</p>\n<p>See, e.g., <a href=\"https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html\">https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486504538550_-626823615","id":"20170207-135538_1056958369","dateCreated":"2017-02-07T13:55:38-0800","dateStarted":"2017-02-07T14:42:46-0800","dateFinished":"2017-02-07T14:42:46-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22985"},{"text":"%md #### RDD (Resilient Distributed Dataset)\n\nThis is a very brief intro to the older, lower-level data analysis approach.\n\nWe'll look more at RDDs, and RDD execution, later.\n\nFirst, let's write out a plain text file with the pagecount data, since the RDD APIs don't have nice pluggable format support...","user":"anonymous","dateUpdated":"2017-02-07T14:42:49-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>RDD (Resilient Distributed Dataset)</h4>\n<p>This is a very brief intro to the older, lower-level data analysis approach.</p>\n<p>We&rsquo;ll look more at RDDs, and RDD execution, later.</p>\n<p>First, let&rsquo;s write out a plain text file with the pagecount data, since the RDD APIs don&rsquo;t have nice pluggable format support&hellip;</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486505839440_269313460","id":"20170207-141719_1913628248","dateCreated":"2017-02-07T14:17:19-0800","dateStarted":"2017-02-07T14:42:49-0800","dateFinished":"2017-02-07T14:42:49-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22986"},{"text":"%sh gunzip data/pageviews-20170120-180000.gz","user":"anonymous","dateUpdated":"2017-02-07T14:27:24-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486505849105_-1873353164","id":"20170207-141729_405213925","dateCreated":"2017-02-07T14:17:29-0800","dateStarted":"2017-02-07T14:27:24-0800","dateFinished":"2017-02-07T14:27:25-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22987"},{"text":"// Let's start by just counting lines:\n\nval file = \"data/pageviews-20170120-180000\"\nsc.textFile(file).count\n","user":"anonymous","dateUpdated":"2017-02-07T14:27:59-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486506092793_-1707390115","id":"20170207-142132_1277034214","dateCreated":"2017-02-07T14:21:32-0800","dateStarted":"2017-02-07T14:27:59-0800","dateFinished":"2017-02-07T14:28:00-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22988"},{"text":"%md Just for contrast, let's look at how we would answer the query \"How many total views were served for pages like Apache\\_\\* (more or less Apache projects)?\"\n\nFirst we want to restrict to English:","user":"anonymous","dateUpdated":"2017-02-07T14:42:54-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Just for contrast, let&rsquo;s look at how we would answer the query &ldquo;How many total views were served for pages like Apache_* (more or less Apache projects)?&rdquo;</p>\n<p>First we want to restrict to English:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486506529543_-46220032","id":"20170207-142849_301239167","dateCreated":"2017-02-07T14:28:49-0800","dateStarted":"2017-02-07T14:42:54-0800","dateFinished":"2017-02-07T14:42:54-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22989"},{"text":"sc.textFile(file)\n    .map(line => line.split(\" \"))\n    .filter(line => (line(0) == \"en\"))\n    .count","user":"anonymous","dateUpdated":"2017-02-07T14:31:20-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486506656211_1792326395","id":"20170207-143056_1256734202","dateCreated":"2017-02-07T14:30:56-0800","dateStarted":"2017-02-07T14:31:16-0800","dateFinished":"2017-02-07T14:31:17-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22990"},{"text":"%md Now let's do the filter for \"Apache\\_\"","user":"anonymous","dateUpdated":"2017-02-07T14:42:57-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now let&rsquo;s do the filter for &ldquo;Apache_&rdquo;</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486506676232_1226760836","id":"20170207-143116_530855144","dateCreated":"2017-02-07T14:31:16-0800","dateStarted":"2017-02-07T14:42:57-0800","dateFinished":"2017-02-07T14:42:57-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22991"},{"text":"sc.textFile(file)\n  .map(line => line.split(\" \"))\n  .filter(line => (line(0) == \"en\"))\n  .filter(line => (line(1).startsWith(\"Apache_\")))\n  .count","user":"anonymous","dateUpdated":"2017-02-07T14:32:07-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486506710413_290479583","id":"20170207-143150_2106740787","dateCreated":"2017-02-07T14:31:50-0800","dateStarted":"2017-02-07T14:32:01-0800","dateFinished":"2017-02-07T14:32:03-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22992"},{"text":"%md So that's the number of distinct page entries ... now let's add up the views:","user":"anonymous","dateUpdated":"2017-02-07T14:43:01-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>So that&rsquo;s the number of distinct page entries &hellip; now let&rsquo;s add up the views:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486506721686_1405127795","id":"20170207-143201_1637510252","dateCreated":"2017-02-07T14:32:01-0800","dateStarted":"2017-02-07T14:43:01-0800","dateFinished":"2017-02-07T14:43:01-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22993"},{"text":"sc.textFile(file)\n  .map(line => line.split(\" \"))\n  .filter(line => (line(0) == \"en\"))\n  .filter(line => (line(1).toLowerCase.startsWith(\"apache_\")))\n  .map(_(2).toInt)\n  .reduce(_ + _)","user":"anonymous","dateUpdated":"2017-02-07T14:32:47-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486506749834_728769877","id":"20170207-143229_1165233492","dateCreated":"2017-02-07T14:32:29-0800","dateStarted":"2017-02-07T14:32:40-0800","dateFinished":"2017-02-07T14:32:41-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22994"},{"text":"%md And let's just check our work with SQL to make sure we get the same number:","user":"anonymous","dateUpdated":"2017-02-07T14:43:03-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>And let&rsquo;s just check our work with SQL to make sure we get the same number:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486506760309_-1544125766","id":"20170207-143240_1187607032","dateCreated":"2017-02-07T14:32:40-0800","dateStarted":"2017-02-07T14:43:03-0800","dateFinished":"2017-02-07T14:43:03-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22995"},{"text":"%sql SELECT SUM(req) FROM parquet.`data/pagecounts` WHERE project = 'en' AND lower(page) LIKE 'apache\\_%'","user":"anonymous","dateUpdated":"2017-02-07T14:33:40-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":true},"editorMode":"ace/mode/sql","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486506785255_2027544246","id":"20170207-143305_1625660226","dateCreated":"2017-02-07T14:33:05-0800","dateStarted":"2017-02-07T14:33:33-0800","dateFinished":"2017-02-07T14:33:35-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22996"},{"text":"%md #### Note some differences:\n\nBasic differences:\n\n* SQL is easier to read and write\n* We had do our own parsing (`line.split(\" \")`) with RDDs. This was an easy case, but more complex cases would require more work and (hopefully) developing reusable modules\n* We had to manage schema ourselves -- e.g., knowing that column 3 was an Int, but represented in our structure as a String, then casting it later\n* The aggregation (reduce) was simple here because we were adding Ints to get an Int, but more complex calculations would require more complex aggregation calls ... GROUP BY would require calls to keyBy and reduce (or aggregate) by key for good performance\n\nSubtle differences:\n\n* Since all of our calls (map/filter/reduce) took Scala (Java) funtions, Spark needs to supply Scala/Java objects as parameters and receives the same as output.\n    * This is intuitive and sensible for a JVM tool __but__ it's not optimal\n* Wouldn't it be cool to pass only the columns needed for an operation?\n    * How about optimizing by doing things like combining the filters?\n    * Or sorting a column based on primitive values, rather than treating it as a sort on Java objects (all fields accessed by reference)\n  \nDataFrame / Dataset does all of these optimizations and more. We'll see more detail later, but take note of the comparison for now.\n  ","user":"anonymous","dateUpdated":"2017-02-07T14:43:07-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Note some differences:</h4>\n<p>Basic differences:</p>\n<ul>\n  <li>SQL is easier to read and write</li>\n  <li>We had do our own parsing (<code>line.split(&quot; &quot;)</code>) with RDDs. This was an easy case, but more complex cases would require more work and (hopefully) developing reusable modules</li>\n  <li>We had to manage schema ourselves &ndash; e.g., knowing that column 3 was an Int, but represented in our structure as a String, then casting it later</li>\n  <li>The aggregation (reduce) was simple here because we were adding Ints to get an Int, but more complex calculations would require more complex aggregation calls &hellip; GROUP BY would require calls to keyBy and reduce (or aggregate) by key for good performance</li>\n</ul>\n<p>Subtle differences:</p>\n<ul>\n  <li>Since all of our calls (map/filter/reduce) took Scala (Java) funtions, Spark needs to supply Scala/Java objects as parameters and receives the same as output.\n    <ul>\n      <li>This is intuitive and sensible for a JVM tool <strong>but</strong> it&rsquo;s not optimal</li>\n    </ul>\n  </li>\n  <li>Wouldn&rsquo;t it be cool to pass only the columns needed for an operation?\n    <ul>\n      <li>How about optimizing by doing things like combining the filters?</li>\n      <li>Or sorting a column based on primitive values, rather than treating it as a sort on Java objects (all fields accessed by reference)</li>\n    </ul>\n  </li>\n</ul>\n<p>DataFrame / Dataset does all of these optimizations and more. We&rsquo;ll see more detail later, but take note of the comparison for now.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1486506813551_578241112","id":"20170207-143333_370800428","dateCreated":"2017-02-07T14:33:33-0800","dateStarted":"2017-02-07T14:43:07-0800","dateFinished":"2017-02-07T14:43:07-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:22997"},{"text":"%md\n","user":"anonymous","dateUpdated":"2017-02-07T14:34:06-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1486506846028_-1522625800","id":"20170207-143406_1228846029","dateCreated":"2017-02-07T14:34:06-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22998"}],"name":"Intro-DF-DS-SQL","id":"2CAVAD8X8","angularObjects":{"2CAVTNYXD:shared_process":[],"2C7K2429Q:shared_process":[],"2C8SPPQZU:shared_process":[],"2C7UX75H1:shared_process":[],"2C8CZHBMK:shared_process":[],"2C8M1YA6S:shared_process":[],"2C8HBGBZH:shared_process":[],"2C8W1YSQF:shared_process":[],"2CA11FFZW:shared_process":[],"2C8GTCYUP:shared_process":[],"2C7JSZ74W:shared_process":[],"2C7NXAQD7:shared_process":[],"2C8BUSWZY:shared_process":[],"2C8BMRSH6:shared_process":[],"2CAD4S1XP:shared_process":[],"2C8DQ16J7:shared_process":[],"2C9YA18WV:shared_process":[],"2CA315FYH:shared_process":[],"2C915WF4P:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}